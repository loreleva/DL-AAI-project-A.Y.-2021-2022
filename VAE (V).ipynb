{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bf0312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bbf770",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7102f70e",
   "metadata": {},
   "source": [
    "# Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660266e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_dataset(portion_train, path_rollouts_csv=\"./DATASET_ROLLOUTS/rollouts.csv\"):\n",
    "    # if dataset for VAE already exists, just load it\n",
    "    if os.path.exists(\"./DATASET_ROLLOUTS/dataset_vae.csv\"):\n",
    "        df_obs = pd.read_csv(\"./DATASET_ROLLOUTS/dataset_vae.csv\", sep=\";\", skipinitialspace=True)\n",
    "        print(f\"Dataset loaded from csv\")\n",
    "    else:\n",
    "        # if not, create it from the main dataset\n",
    "        \n",
    "        # load into dataframe the csv of the rollouts\n",
    "        df_rollouts = pd.read_csv(path_rollouts_csv, sep=\";\", skipinitialspace=True)\n",
    "        # init the resulting dataframe\n",
    "        df_obs = pd.DataFrame(columns=[\"Path image observation\"])\n",
    "        \n",
    "        # iterate over each rollout\n",
    "        i = 0\n",
    "        for path_obs_csv in df_rollouts[\"Path csv\"]:\n",
    "            # load into dataframe the csv of the rollouts' observations\n",
    "            new_df = pd.read_csv(path_obs_csv, sep=\";\", skipinitialspace=True)\n",
    "            # add the observations' path to the resulting dataframe\n",
    "            df_obs = pd.concat([df_obs, new_df[[\"Path image observation\"]]], axis=0)\n",
    "            \n",
    "            if (i+1) % 1000 == 0:\n",
    "                print(f\"Observation {i+1}/10000\")\n",
    "            i+=1\n",
    "            \n",
    "        print(f\"Creating new csv\")\n",
    "        # save the resulting dataframe into csv\n",
    "        df_obs.to_csv(\"./DATASET_ROLLOUTS/dataset_vae.csv\", sep=\";\", index=False)\n",
    "        print(f\"Csv created\")\n",
    "        \n",
    "    # divide the observations into trainset and testset\n",
    "    n_train = int(len(df_obs) * portion_train)\n",
    "    trainset = Trainset(df_obs.sample(n_train))\n",
    "    print(f\"Train set created\")\n",
    "    testset = None\n",
    "    if portion_train < 1:\n",
    "        df_obs = df_obs.drop(list(trainset.df.index.values))\n",
    "        testset = Testset(df_obs)\n",
    "        print(f\"Test set created\")\n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ec4177",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.transform = transforms.PILToTensor()\n",
    "        self.df = df\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # returns the image's tensor, normalized\n",
    "        img = Image.open(self.df.iloc[idx, 0])\n",
    "        return self.transform(img).float()/255\n",
    "    \n",
    "class Testset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.transform = transforms.PILToTensor()\n",
    "        self.df = df\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # returns the image's tensor, normalized\n",
    "        img = Image.open(self.df.iloc[idx, 0])\n",
    "        return self.transform(img).float()/255     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc76745",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de26756",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,\n",
    "                               out_channels=32,\n",
    "                               kernel_size=4,\n",
    "                               stride=2\n",
    "                              )\n",
    "        self.conv2 = nn.Conv2d(in_channels=32,\n",
    "                               out_channels=64,\n",
    "                               kernel_size=4,\n",
    "                               stride=2\n",
    "                              )\n",
    "        self.conv3 = nn.Conv2d(in_channels=64,\n",
    "                               out_channels=128,\n",
    "                               kernel_size=4,\n",
    "                               stride=2\n",
    "                              )\n",
    "        self.conv4 = nn.Conv2d(in_channels=128,\n",
    "                               out_channels=256,\n",
    "                               kernel_size=4,\n",
    "                               stride=2\n",
    "                              )\n",
    "        \n",
    "        self.fc_mu = nn.Linear(in_features=2*2*256, out_features=latent_dim)\n",
    "        self.fc_logvar = nn.Linear(in_features=2*2*256, out_features=latent_dim)\n",
    "        \n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.conv1(x))\n",
    "        x = self.activation(self.conv2(x))\n",
    "        x = self.activation(self.conv3(x))\n",
    "        x = self.activation(self.conv4(x))\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x_mu = self.fc_mu(x)\n",
    "        x_logvar = self.fc_logvar(x)\n",
    "        \n",
    "        return x_mu, x_logvar\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a59090",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8c9308",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(in_features=latent_dim, out_features=1024)\n",
    "        \n",
    "        self.conv4 = nn.ConvTranspose2d(in_channels=1024,\n",
    "                                       out_channels=128,\n",
    "                                       kernel_size=5,\n",
    "                                       stride=2)\n",
    "        self.conv3 = nn.ConvTranspose2d(in_channels=128,\n",
    "                                       out_channels=64,\n",
    "                                       kernel_size=5,\n",
    "                                       stride=2)\n",
    "        self.conv2 = nn.ConvTranspose2d(in_channels=64,\n",
    "                                       out_channels=32,\n",
    "                                       kernel_size=6,\n",
    "                                       stride=2)\n",
    "        self.conv1 = nn.ConvTranspose2d(in_channels=32,\n",
    "                                       out_channels=3,\n",
    "                                       kernel_size=6,\n",
    "                                       stride=2)\n",
    "        \n",
    "        self.ReLU_activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = x.view(x.shape[0], 1024, 1, 1)\n",
    "        x = self.ReLU_activation(self.conv4(x))\n",
    "        x = self.ReLU_activation(self.conv3(x))\n",
    "        x = self.ReLU_activation(self.conv2(x))\n",
    "        x = torch.sigmoid(self.conv1(x))\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e6c552",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8a8021",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(latent_dim)\n",
    "        self.decoder = Decoder(latent_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent_mu, latent_logvar = self.encoder(x)\n",
    "        latent = self.latent_sample(latent_mu, latent_logvar)\n",
    "        x_recon = self.decoder(latent)\n",
    "        return x_recon, latent_mu, latent_logvar\n",
    "        \n",
    "    def latent_sample(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = (logvar * 0.5).exp()\n",
    "            return torch.distributions.Normal(loc=mu, scale=std).rsample()\n",
    "        else:\n",
    "            return mu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcac477",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e64fa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss of the vae with mse\n",
    "def vae_loss(recon_x, x, mu, logvar, variational_beta):\n",
    "    recon_loss = F.mse_loss(recon_x.view(-1,12288), x.view(-1,12288))\n",
    "    kldivergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_loss + variational_beta*kldivergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afe8e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain trainset and testset\n",
    "trainset, testset = Create_dataset(portion_train=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f44c182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting with beta at 0, after obtaining a decent reconstruction, increase it incrementally until 1\n",
    "var_beta = 0\n",
    "latent_dim = 512\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d744dad8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vae = VariationalAutoencoder(latent_dim=latent_dim).to(device)\n",
    "\n",
    "vae.train()\n",
    "optimizer = optim.Adam(params=vae.parameters(), lr=lr)\n",
    "    \n",
    "i=0     \n",
    "while(True):\n",
    "    losses = []\n",
    "    n_batch = 1\n",
    "    train_loader = DataLoader(trainset, batch_size=100, shuffle=True)\n",
    "    for img_batch in train_loader:\n",
    "        img_batch = img_batch.to(device)\n",
    "        \n",
    "        img_batch_recon, latent_mu, latent_logvar = vae(img_batch)\n",
    "        \n",
    "        loss = vae_loss(img_batch_recon, img_batch, latent_mu, latent_logvar, var_beta)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "    print(f\"EPOCH: {i+1} MEAN LOSSES EPOCH: {sum(losses)/len(losses)}\")\n",
    "    print(f\"Loss: {loss.item()}\")\n",
    "    i+=1\n",
    "    torch.save(vae, f\"./BACKUP_MODELS/vae\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
