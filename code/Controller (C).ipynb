{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3594aeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gym, random\n",
    "from multiprocessing import Process, Queue\n",
    "import itertools, cma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4721b0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decdbea5",
   "metadata": {},
   "source": [
    "# INIT VAE and MDNRNN models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ff2c2f",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefc2a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,\n",
    "                               out_channels=32,\n",
    "                               kernel_size=4,\n",
    "                               stride=2\n",
    "                              )\n",
    "        self.conv2 = nn.Conv2d(in_channels=32,\n",
    "                               out_channels=64,\n",
    "                               kernel_size=4,\n",
    "                               stride=2\n",
    "                              )\n",
    "        self.conv3 = nn.Conv2d(in_channels=64,\n",
    "                               out_channels=128,\n",
    "                               kernel_size=4,\n",
    "                               stride=2\n",
    "                              )\n",
    "        self.conv4 = nn.Conv2d(in_channels=128,\n",
    "                               out_channels=256,\n",
    "                               kernel_size=4,\n",
    "                               stride=2\n",
    "                              )\n",
    "        \n",
    "        self.fc_mu = nn.Linear(in_features=2*2*256, out_features=latent_dim)\n",
    "        self.fc_logvar = nn.Linear(in_features=2*2*256, out_features=latent_dim)\n",
    "        \n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.conv1(x))\n",
    "        x = self.activation(self.conv2(x))\n",
    "        x = self.activation(self.conv3(x))\n",
    "        x = self.activation(self.conv4(x))\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x_mu = self.fc_mu(x)\n",
    "        x_logvar = self.fc_logvar(x)\n",
    "        \n",
    "        return x_mu, x_logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f0e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(in_features=latent_dim, out_features=1024)\n",
    "        \n",
    "        self.conv4 = nn.ConvTranspose2d(in_channels=1024,\n",
    "                                       out_channels=128,\n",
    "                                       kernel_size=5,\n",
    "                                       stride=2)\n",
    "        self.conv3 = nn.ConvTranspose2d(in_channels=128,\n",
    "                                       out_channels=64,\n",
    "                                       kernel_size=5,\n",
    "                                       stride=2)\n",
    "        self.conv2 = nn.ConvTranspose2d(in_channels=64,\n",
    "                                       out_channels=32,\n",
    "                                       kernel_size=6,\n",
    "                                       stride=2)\n",
    "        self.conv1 = nn.ConvTranspose2d(in_channels=32,\n",
    "                                       out_channels=3,\n",
    "                                       kernel_size=6,\n",
    "                                       stride=2)\n",
    "        \n",
    "        self.ReLU_activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = x.view(x.shape[0], 1024, 1, 1)\n",
    "        x = self.ReLU_activation(self.conv4(x))\n",
    "        x = self.ReLU_activation(self.conv3(x))\n",
    "        x = self.ReLU_activation(self.conv2(x))\n",
    "        x = torch.sigmoid(self.conv1(x))\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f327e625",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(latent_dim)\n",
    "        self.decoder = Decoder(latent_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent_mu, latent_logvar = self.encoder(x)\n",
    "        latent = self.latent_sample(latent_mu, latent_logvar)\n",
    "        x_recon = self.decoder(latent)\n",
    "        return x_recon, latent_mu, latent_logvar\n",
    "        \n",
    "    def latent_sample(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = (logvar * 0.5).exp()\n",
    "            return torch.distributions.Normal(loc=mu, scale=std).rsample()\n",
    "        else:\n",
    "            return mu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d523185",
   "metadata": {},
   "source": [
    "## MDNRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b0ad41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDNRNN(nn.Module):\n",
    "    def __init__(self, hidden_units, z_dim, num_layers, n_gaussians):\n",
    "        super().__init__()\n",
    "        self.hidden_units = hidden_units\n",
    "        self.z_dim = z_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.n_gaussians = n_gaussians\n",
    "        self.hidden = None\n",
    "        self.cell = None\n",
    "        \n",
    "        # RNN\n",
    "        self.lstm = nn.LSTM(self.z_dim+1, self.hidden_units, batch_first=True)\n",
    "        \n",
    "        # MDN\n",
    "        # weights for the results of the gaussians\n",
    "        self.z_pi = nn.Linear(self.hidden_units, self.n_gaussians*(self.z_dim))\n",
    "        # parameters of the gaussians\n",
    "        self.z_sigma = nn.Linear(self.hidden_units, self.n_gaussians*(self.z_dim))\n",
    "        self.z_mu = nn.Linear(self.hidden_units, self.n_gaussians*(self.z_dim))\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.hidden == None and self.cell == None:\n",
    "            z, state = self.lstm(x)\n",
    "            self.hidden, self.cell = state\n",
    "        else:\n",
    "            z, state = self.lstm(x, (self.hidden, self.cell))\n",
    "            self.hidden, self.cell = state\n",
    "        z, _ = nn.utils.rnn.pad_packed_sequence(z, batch_first=True)\n",
    "        x, _ = nn.utils.rnn.pad_packed_sequence(x, batch_first=True)\n",
    "        seq_len = x.shape[1]\n",
    "        \n",
    "        pi = self.z_pi(z).view(-1, seq_len, self.n_gaussians, self.z_dim)\n",
    "        # transform the pi values to let them sum to 1\n",
    "        pi = F.softmax(pi, dim=2)\n",
    "        # transform sigmas with exponential to ensures they are all positive\n",
    "        sigma = torch.exp(self.z_sigma(z)).view(-1, seq_len, self.n_gaussians, self.z_dim)\n",
    "        # compute mus\n",
    "        mu = self.z_mu(z).view(-1, seq_len, self.n_gaussians, self.z_dim)\n",
    "        return pi, sigma, mu\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.hidden = None\n",
    "        self.cell = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8972dd4b",
   "metadata": {},
   "source": [
    "# Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef11e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Controller(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        # input dimensions is size_z + size_h\n",
    "        self.input_dim = input_dim\n",
    "        self.fc = nn.Linear(input_dim, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc(x))\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4290ee3",
   "metadata": {},
   "source": [
    "# CMAES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51195015",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CMAES():\n",
    "    def __init__(self, input_dim, popsize, q_inp, q_res, sigma=0.10):\n",
    "        self.popsize = popsize\n",
    "        self.input_dim = input_dim\n",
    "        self.num_parameters = (self.input_dim + 1) * 5\n",
    "        self.temp_best_parameters = None\n",
    "        self.temp_best_fitness = 0\n",
    "        # population is a list of lists of type: [controllers, list of parameters]\n",
    "        self.population = [[Controller(input_dim), None] for i in range(self.popsize)]\n",
    "        # queues for the concurrent execution\n",
    "        self.q_inp = q_inp\n",
    "        self.q_res = q_res\n",
    "        # init cma-es solver\n",
    "        self.solver = cma.CMAEvolutionStrategy(self.num_parameters * [0], 0.10, {\"popsize\" : self.popsize})\n",
    "        # init population\n",
    "        self.sample_population()\n",
    "        \n",
    "    def start_optimization(self):\n",
    "        # execute the optimization and terminates when a fitness score of >= 50 is obtained\n",
    "        \n",
    "        controller_parameters, fitness = self.run_step()\n",
    "        epochs = 0\n",
    "        print(f\"EPOCH: {epochs} FITNESS: {fitness}\")\n",
    "        epochs += 1\n",
    "        while(fitness < 50):\n",
    "            # run the optimization step\n",
    "            controller_parameters, fitness = self.run_step()\n",
    "            \n",
    "            # save fitness score and parameters if they are better\n",
    "            if fitness > self.temp_best_fitness:\n",
    "                self.temp_best_fitness = fitness\n",
    "                self.temp_best_parameters = controller_parameters\n",
    "                \n",
    "            print(f\"EPOCH: {epochs} FITNESS: {fitness} BEST FITNESS {self.temp_best_fitness}\")\n",
    "            epochs += 1\n",
    "        return self.temp_best_parameters\n",
    "        \n",
    "        \n",
    "    def run_step(self):\n",
    "        # compute the fitness scores and update the population\n",
    "\n",
    "        # run in parallel all the controllers\n",
    "        for controller in self.population:\n",
    "            q_inp.put(controller)\n",
    "        \n",
    "        # retrieve the controllers' fitness score\n",
    "        fitness_scores = []\n",
    "        finished_controllers_param = []\n",
    "        num_finished = 0\n",
    "        while(num_finished != self.popsize):\n",
    "            # obtain result\n",
    "            controller, fitness = q_res.get()\n",
    "            # save fitness scores as negative sign, solver performs minimization\n",
    "            fitness_scores.append(-fitness)\n",
    "            # append controller parameters to associate them to fitness score\n",
    "            finished_controllers_param.append(controller[1])\n",
    "            num_finished += 1\n",
    "            print(f\"FINISHED: {num_finished}/{self.popsize}\")\n",
    "        \n",
    "        # update solver\n",
    "        self.solver.tell(finished_controllers_param, fitness_scores)\n",
    "    \n",
    "        # sample new population\n",
    "        self.sample_population()\n",
    "        \n",
    "        # return solver parameters and best fitness score\n",
    "        return self.solver.result[0], -self.solver.result[1]\n",
    "        \n",
    "    def sample_population(self):\n",
    "        # generate population from the parameters samples returned by the solver\n",
    "        \n",
    "        # obtain the new population's parameters\n",
    "        new_samples_parameters = self.solver.ask()\n",
    "        \n",
    "        # create the new population\n",
    "        for x in range(self.popsize):\n",
    "            # associate new parameters to controller\n",
    "            self.population[x][1] = new_samples_parameters[x]\n",
    "            \n",
    "            # transform parameters from numpy to torch tensor\n",
    "            new_parameters = torch.from_numpy(new_samples_parameters[x]).reshape(-1, self.input_dim + 1).to(device)\n",
    "            \n",
    "            # create new state dict\n",
    "            new_state_dict = {\n",
    "                \"fc.weight\" : new_parameters[:, :-1],\n",
    "                \"fc.bias\" : new_parameters[:, -1]\n",
    "            }\n",
    "            # load new parameters into controller\n",
    "            self.population[x][0].load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7728a84a",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0243aba",
   "metadata": {},
   "source": [
    "## Definition of the function to be runned in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47974b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_function(q_inp, q_res, vae, mdnrnn):\n",
    "    # run 30 rollouts\n",
    "    rollouts = 30\n",
    "    \n",
    "    # controller is a tuple (controller, list of parameters)\n",
    "    controller = q_inp.get()\n",
    "    \n",
    "    # run while a signal to terminate is not received from the queue\n",
    "    while (controller != None):\n",
    "        fitness_scores = []\n",
    "        for i in range(rollouts):\n",
    "            fitness = run_rollout(controller[0], vae, mdnrnn)\n",
    "            fitness_scores.append(fitness)\n",
    "            \n",
    "            print(f\"ROLLOUT: {i}/{rollouts}\")\n",
    "            \n",
    "        # return the tuple (controller, parameters) and the average fitness score of the rollouts\n",
    "        q_res.put((controller, sum(fitness_scores)/rollouts))\n",
    "         \n",
    "        controller = q_inp.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad4bee4-77a0-48d6-9118-82b997148df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VariationalAutoencoder(latent_dim=512).to(device)\n",
    "\n",
    "lr = 1e-3\n",
    "hidden_units = 1024\n",
    "z_dim = 512\n",
    "n_gaussians = 16\n",
    "\n",
    "mdnrnn = MDNRNN(hidden_units=hidden_units, z_dim=z_dim, num_layers=1, n_gaussians=n_gaussians).to(device)\n",
    "\n",
    "controller = Controller(512+1024).to(device)\n",
    "#run_rollout("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee677a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rollout(controller, vae, mdnrnn):\n",
    "    # runs a single rollout using the models and returns the cumulative reward\n",
    "    \n",
    "    # init mdnrnn\n",
    "    mdnrnn.reset_state()\n",
    "    \n",
    "    # init gym environment\n",
    "    env = gym.make(\"procgen:procgen-leaper-v0\", start_level=0, num_levels=0, render_mode=\"rgb_array\")\n",
    "    obs = env.reset()\n",
    "    \n",
    "    # map actions to procgen actions\n",
    "    action_to_procgen = {0: 2, #left,\n",
    "                    1: 3, #down,\n",
    "                    2: 5, #up,\n",
    "                    3: 7, #right,\n",
    "                    4: 9, #idle\n",
    "                   }\n",
    "    \n",
    "    # start with idle action\n",
    "    action = 9 \n",
    "    \n",
    "    # execute rollout\n",
    "    terminated = False\n",
    "    cumulative_reward = 0\n",
    "\n",
    "    # init hidden state of LSTM\n",
    "    hidden_state_rnn = torch.zeros(1, 1, mdnrnn.hidden_units)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        while not terminated:\n",
    "            # compute latent vector of observation\n",
    "            z, _ = vae.encoder((torch.from_numpy(obs).permute(2, 0, 1).float()/255).unsqueeze(0).to(device))\n",
    "\n",
    "            # concat z and hidden state\n",
    "            input_controller = torch.cat((z, hidden_state_rnn.squeeze(0)), dim=1).to(device)\n",
    "\n",
    "            # execute controller and retrieve action with max value\n",
    "            res = controller(input_controller)\n",
    "            action = action_to_procgen[torch.argmax(res).item()]\n",
    "\n",
    "            # perform action and retrieve environment informations\n",
    "            obs, reward, terminated, info = env.step(action)\n",
    "            cumulative_reward += reward\n",
    "            \n",
    "            # pack input for mdnrnn\n",
    "            input_rnn = torch.cat((z, torch.Tensor([[action]]).to(device)), dim=1)\n",
    "            packed_input = nn.utils.rnn.pack_padded_sequence(input_rnn.unsqueeze(0), [1], batch_first=True, enforce_sorted=False)\n",
    "            \n",
    "            # execute mdnrnn and take the hidden state\n",
    "            mdnrnn(packed_input)\n",
    "            hidden_state_rnn = mdnrnn.hidden\n",
    "            \n",
    "            \n",
    "    return cumulative_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9b8f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_processes(q_inp, q_res, vae, mdnrnn):\n",
    "    # function which initialize the parallel processes\n",
    "    \n",
    "    processes = []\n",
    "    for x in range(num_processes):\n",
    "        processes.append(Process(target=proc_function, args=(q_inp, q_res, vae, mdnrnn)))\n",
    "        processes[x].start()\n",
    "    return processes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8bf440",
   "metadata": {},
   "source": [
    "## Execute Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c134978",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the models\n",
    "vae = torch.load(\"./BACKUP_MODELS/vae\").to(device)\n",
    "mdnrnn = torch.load(\"./BACKUP_MODELS/mdnrnn\").to(device)\n",
    "\n",
    "# define number of concurrent processes\n",
    "num_processes = 2\n",
    "\n",
    "# init queues\n",
    "q_inp = Queue()\n",
    "q_res = Queue()\n",
    "\n",
    "# init concurrent processes\n",
    "processes = init_processes(q_inp, q_res, vae, mdnrnn)\n",
    "\n",
    "# init optimizer and run it\n",
    "es = CMAES(512+1024, 30, q_inp, q_res)\n",
    "best_parameters = es.start_optimization()\n",
    "\n",
    "# kill the concurrent processes\n",
    "for x in processes:\n",
    "    x.kill()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1fbc86",
   "metadata": {},
   "source": [
    "## Save the best controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aab98af",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_controller = Controller(512+1024)\n",
    "\n",
    "# fitness of >=50 is not reached, here I am saving the temporary best controller\n",
    "new_parameters = torch.from_numpy(es.temp_best_parameters).reshape(-1, 512+1024 + 1).to(device)\n",
    "\n",
    "# create new state dict\n",
    "new_state_dict = {\n",
    "    \"fc.weight\" : new_parameters[:, :-1],\n",
    "    \"fc.bias\" : new_parameters[:, -1]\n",
    "}\n",
    "\n",
    "# load new parameters into controller\n",
    "best_controller.load_state_dict(new_state_dict)\n",
    "\n",
    "# save the model\n",
    "torch.save(best_controller, f\"./BACKUP_MODELS/controller\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ec2d35",
   "metadata": {},
   "source": [
    "# Run test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e509c7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede5b011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the models\n",
    "vae = torch.load(\"./BACKUP_MODELS/vae\").to(device)\n",
    "mdnrnn = torch.load(\"./BACKUP_MODELS/mdnrnn\").to(device)\n",
    "controller = torch.load(f\"./BACKUP_MODELS/controller\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03186ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_rollout(controller, vae, mdnrnn):\n",
    "    # runs a single rollout and return 1 if win, 0 if lose\n",
    "    \n",
    "    mdnrnn.reset_state()\n",
    "    env = gym.make(\"procgen:procgen-leaper-v0\", start_level=0, num_levels=0, render_mode=\"rgb_array\")\n",
    "    obs = env.reset()\n",
    "    action_to_procgen = {0: 2, #left,\n",
    "                    1: 3, #down,\n",
    "                    2: 5, #up,\n",
    "                    3: 7, #right,\n",
    "                    4: 9, #idle\n",
    "                   }\n",
    "    \n",
    "    # start with idle action\n",
    "    action = 9 \n",
    "    terminated = False\n",
    "\n",
    "    # init hidden state of LSTM\n",
    "    hidden_state_rnn = torch.zeros(1, 1, mdnrnn.hidden_units)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        while not terminated:\n",
    "            # compute latent vector of observation\n",
    "            z, _ = vae.encoder((torch.from_numpy(obs).permute(2, 0, 1).float()/255).unsqueeze(0).to(device))\n",
    "\n",
    "            # concat z and hidden state\n",
    "            input_controller = torch.cat((z, hidden_state_rnn.squeeze(0)), dim=1).to(device)\n",
    "\n",
    "            # execute controller and retrieve action with max value\n",
    "            res = controller(input_controller)\n",
    "            action = action_to_procgen[torch.argmax(res).item()]\n",
    "\n",
    "            # perform action and retrieve environment informations\n",
    "            obs, reward, terminated, info = env.step(action)\n",
    "            cumulative_reward += reward\n",
    "            \n",
    "            # pack input for mdnrnn\n",
    "            input_rnn = torch.cat((z, torch.Tensor([[action]]).to(device)), dim=1)\n",
    "            packed_input = nn.utils.rnn.pack_padded_sequence(input_rnn.unsqueeze(0), [1], batch_first=True, enforce_sorted=False)\n",
    "            \n",
    "            # execute mdnrnn and take the hidden state\n",
    "            mdnrnn(packed_input)\n",
    "            hidden_state_rnn = mdnrnn.hidden\n",
    "    \n",
    "    if reward > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a9f2da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# execute the rollouts and retun the number of wins\n",
    "num_rollouts = 100\n",
    "num_win = 0\n",
    "for i in range(num_rollouts):\n",
    "    num_win += run_test_rollout(controller, vae, mdnrnn)\n",
    "    print(f\"ROLLOUT: {i+1}/{num_rollouts} NUM WINS: {num_win}\")\n",
    "    \n",
    "print(f\"NUMBER OF WINS: {num_win}/{num_rollouts}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
