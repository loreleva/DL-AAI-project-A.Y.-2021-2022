{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91edb946",
   "metadata": {},
   "source": [
    "# MDNRNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4c1826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02cd2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1d0713",
   "metadata": {},
   "source": [
    "## Init VAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc394229",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,\n",
    "                               out_channels=32,\n",
    "                               kernel_size=4,\n",
    "                               stride=2\n",
    "                              )\n",
    "        self.conv2 = nn.Conv2d(in_channels=32,\n",
    "                               out_channels=64,\n",
    "                               kernel_size=4,\n",
    "                               stride=2\n",
    "                              )\n",
    "        self.conv3 = nn.Conv2d(in_channels=64,\n",
    "                               out_channels=128,\n",
    "                               kernel_size=4,\n",
    "                               stride=2\n",
    "                              )\n",
    "        self.conv4 = nn.Conv2d(in_channels=128,\n",
    "                               out_channels=256,\n",
    "                               kernel_size=4,\n",
    "                               stride=2\n",
    "                              )\n",
    "        \n",
    "        self.fc_mu = nn.Linear(in_features=2*2*256, out_features=latent_dim)\n",
    "        self.fc_logvar = nn.Linear(in_features=2*2*256, out_features=latent_dim)\n",
    "        \n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.conv1(x))\n",
    "        x = self.activation(self.conv2(x))\n",
    "        x = self.activation(self.conv3(x))\n",
    "        x = self.activation(self.conv4(x))\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x_mu = self.fc_mu(x)\n",
    "        x_logvar = self.fc_logvar(x)\n",
    "        \n",
    "        return x_mu, x_logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d0dfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(in_features=latent_dim, out_features=1024)\n",
    "        \n",
    "        self.conv4 = nn.ConvTranspose2d(in_channels=1024,\n",
    "                                       out_channels=128,\n",
    "                                       kernel_size=5,\n",
    "                                       stride=2)\n",
    "        self.conv3 = nn.ConvTranspose2d(in_channels=128,\n",
    "                                       out_channels=64,\n",
    "                                       kernel_size=5,\n",
    "                                       stride=2)\n",
    "        self.conv2 = nn.ConvTranspose2d(in_channels=64,\n",
    "                                       out_channels=32,\n",
    "                                       kernel_size=6,\n",
    "                                       stride=2)\n",
    "        self.conv1 = nn.ConvTranspose2d(in_channels=32,\n",
    "                                       out_channels=3,\n",
    "                                       kernel_size=6,\n",
    "                                       stride=2)\n",
    "        \n",
    "        self.ReLU_activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = x.view(x.shape[0], 1024, 1, 1)\n",
    "        x = self.ReLU_activation(self.conv4(x))\n",
    "        x = self.ReLU_activation(self.conv3(x))\n",
    "        x = self.ReLU_activation(self.conv2(x))\n",
    "        x = torch.sigmoid(self.conv1(x))\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1934c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(latent_dim)\n",
    "        self.decoder = Decoder(latent_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent_mu, latent_logvar = self.encoder(x)\n",
    "        latent = self.latent_sample(latent_mu, latent_logvar)\n",
    "        x_recon = self.decoder(latent)\n",
    "        return x_recon, latent_mu, latent_logvar\n",
    "        \n",
    "    def latent_sample(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = (logvar * 0.5).exp()\n",
    "            return torch.distributions.Normal(loc=mu, scale=std).rsample()\n",
    "        else:\n",
    "            return mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb712e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = torch.load(\"./BACKUP_MODELS/vae\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9605b18e",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32530f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_dataset(vae, portion_train, path_rollouts_csv=\"./DATASET_ROLLOUTS/rollouts.csv\"):\n",
    "    # load dataset from csv if it already exists\n",
    "    if os.path.exists(\"./DATASET_ROLLOUTS/dataset_rnn.csv\"):\n",
    "        res_df = pd.read_csv(\"./DATASET_ROLLOUTS/dataset_rnn.csv\", sep=\";\", skipinitialspace=True)\n",
    "        print(f\"Dataset loaded from csv\")\n",
    "    else:\n",
    "        transform = transforms.PILToTensor()\n",
    "        df_rollouts = pd.read_csv(path_rollouts_csv, sep=\";\", skipinitialspace=True)\n",
    "        res_paths = []\n",
    "        i = 0\n",
    "        # iterate for each rollout\n",
    "        for idx_roll in range(len(df_rollouts)):\n",
    "            # retrieve paths of the rollout\n",
    "            path_obs_csv = df_rollouts.iloc[idx_roll, 2]\n",
    "            path_obs = df_rollouts.iloc[idx_roll, 1]\n",
    "            \n",
    "            # load csv rollout\n",
    "            obs_df = pd.read_csv(path_obs_csv, sep=\";\", skipinitialspace=True)\n",
    "            \n",
    "            # stack each frame of the rollout to be computed in batch with the vae\n",
    "            stack_frames = []\n",
    "            stack_next_frames = []\n",
    "            \n",
    "            # add each frame to be stacked\n",
    "            for idx in range(len(obs_df)):\n",
    "                stack_frames.append(transform(Image.open(obs_df.iloc[idx, 1])).float()/255)\n",
    "                stack_next_frames.append(transform(Image.open(obs_df.iloc[idx, 3])).float()/255)\n",
    "            \n",
    "            # stack frames\n",
    "            stack_frames = torch.stack(stack_frames)\n",
    "            stack_next_frames = torch.stack(stack_next_frames)\n",
    "            \n",
    "            # compute mu and sigma\n",
    "            with torch.no_grad():\n",
    "                frame_mu, frame_sigma = vae.encoder(stack_frames.to(device))\n",
    "                next_frame_mu, next_frame_sigma = vae.encoder(stack_next_frames.to(device))\n",
    "                \n",
    "            # create df of the results\n",
    "            new_obs_df = pd.concat([pd.DataFrame(frame_mu.cpu().detach().numpy()),\n",
    "                                pd.DataFrame(frame_sigma.cpu().detach().numpy()),\n",
    "                                pd.DataFrame(next_frame_mu.cpu().detach().numpy()),\n",
    "                                pd.DataFrame(next_frame_sigma.cpu().detach().numpy()),\n",
    "                                obs_df[[\"Action\"]]],\n",
    "                                axis=1\n",
    "                               )\n",
    "            \n",
    "            # save df into rollout directory\n",
    "            path_roll_csv = os.path.join(path_obs, \"rnn.csv\")\n",
    "            new_obs_df.to_csv(path_roll_csv, sep=\";\", index=False)\n",
    "            \n",
    "            # add result to main dataframe\n",
    "            res_paths.append(path_roll_csv)\n",
    "            \n",
    "            print(f\"Observation {i+1}/10000\")\n",
    "            i+=1\n",
    "            \n",
    "        # save resulting dataframes into csv\n",
    "        res_df = pd.DataFrame(res_paths, columns=[\"Path rollout csv\"])\n",
    "        res_df.to_csv(\"./DATASET_ROLLOUTS/dataset_rnn.csv\", sep=\";\", index=False)\n",
    "        \n",
    "    # create train and test set\n",
    "    n_train = int(len(res_df) * portion_train)\n",
    "    trainset = Trainset(res_df)\n",
    "    print(\"Train set created\")\n",
    "    testset = None\n",
    "    if portion_train < 1:\n",
    "        res_df = res_df.drop(list(trainset.df.index.values))\n",
    "        testset = Testset(res_df)\n",
    "        print(\"Test set created\")\n",
    "    return trainset, testset\n",
    "\n",
    "class Trainset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        rollout_df = pd.read_csv(self.df.iloc[idx, 0], sep=\";\", skipinitialspace=True)\n",
    "        \n",
    "        # retrieve tensors from dataframe\n",
    "        frame_mu = torch.from_numpy(rollout_df.iloc[:, :512].to_numpy().astype(np.float32)).to(device)\n",
    "        frame_sigma = torch.from_numpy(rollout_df.iloc[:, 512:1024].to_numpy().astype(np.float32)).to(device)\n",
    "        next_frame_mu = torch.from_numpy(rollout_df.iloc[:, 1024:1536].to_numpy().astype(np.float32)).to(device)\n",
    "        next_frame_sigma = torch.from_numpy(rollout_df.iloc[:, 1536:2048].to_numpy().astype(np.float32)).to(device)\n",
    "        action = torch.from_numpy(rollout_df[[\"Action\"]].to_numpy().astype(np.float32)).to(device) / 5\n",
    "        \n",
    "        # compute returning tensors, by sampling x each time from mu and sigma\n",
    "        std = (frame_sigma * 0.5).exp()\n",
    "        x = torch.distributions.Normal(loc=frame_mu, scale=std).rsample()\n",
    "        x = torch.cat((x, action), dim=1)\n",
    "        y = next_frame_mu\n",
    "        return (x,y)\n",
    "    \n",
    "class Testset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        rollout_df = pd.read_csv(self.df.iloc[idx, 0], sep=\";\", skipinitialspace=True)\n",
    "        \n",
    "        # retrieve tensors from dataframe\n",
    "        frame_mu = torch.from_numpy(rollout_df.iloc[:, :512].to_numpy().astype(np.float32)).to(device)\n",
    "        frame_sigma = torch.from_numpy(rollout_df.iloc[:, 512:1024].to_numpy().astype(np.float32)).to(device)\n",
    "        next_frame_mu = torch.from_numpy(rollout_df.iloc[:, 1024:1536].to_numpy().astype(np.float32)).to(device)\n",
    "        next_frame_sigma = torch.from_numpy(rollout_df.iloc[:, 1536:2048].to_numpy().astype(np.float32)).to(device)\n",
    "        \n",
    "        # tensor of normalized actions\n",
    "        action = torch.from_numpy(rollout_df[[\"Action\"]].to_numpy().astype(np.float32)).to(device)\n",
    "        \n",
    "        # compute returning tensors, by sampling x each time from mu and sigma\n",
    "        std = (frame_sigma * 0.5).exp()\n",
    "        x = torch.distributions.Normal(loc=frame_mu, scale=std).rsample()\n",
    "        x = torch.cat((x, action), dim=1)\n",
    "        y = next_frame_mu\n",
    "        return (x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf8cfc0",
   "metadata": {},
   "source": [
    "## Init MDRNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c41d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDNRNN(nn.Module):\n",
    "    def __init__(self, hidden_units, z_dim, num_layers, n_gaussians):\n",
    "        super().__init__()\n",
    "        self.hidden_units = hidden_units\n",
    "        self.z_dim = z_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.n_gaussians = n_gaussians\n",
    "        self.hidden = None\n",
    "        self.cell = None\n",
    "        \n",
    "        # RNN\n",
    "        self.lstm = nn.LSTM(self.z_dim+1, self.hidden_units, batch_first=True)\n",
    "        \n",
    "        # MDN\n",
    "        # weights for the results of the gaussians\n",
    "        self.z_pi = nn.Linear(self.hidden_units, self.n_gaussians*(self.z_dim))\n",
    "        # parameters of the gaussians\n",
    "        self.z_sigma = nn.Linear(self.hidden_units, self.n_gaussians*(self.z_dim))\n",
    "        self.z_mu = nn.Linear(self.hidden_units, self.n_gaussians*(self.z_dim))\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # init the lstm if it is the first run of the sequence\n",
    "        if self.hidden == None and self.cell == None:\n",
    "            z, state = self.lstm(x)\n",
    "            self.hidden, self.cell = state\n",
    "        else:\n",
    "            # otherwise run the lstm with the current hidden and cell states\n",
    "            z, state = self.lstm(x, (self.hidden, self.cell))\n",
    "            self.hidden, self.cell = state\n",
    "        \n",
    "        # unpack values from the packed sequences\n",
    "        z, _ = nn.utils.rnn.pad_packed_sequence(z, batch_first=True)\n",
    "        x, _ = nn.utils.rnn.pad_packed_sequence(x, batch_first=True)\n",
    "        seq_len = x.shape[1]\n",
    "        \n",
    "        # compute the values of pi\n",
    "        pi = self.z_pi(z).view(-1, seq_len, self.n_gaussians, self.z_dim)\n",
    "        # transform the pi values to let them sum to 1\n",
    "        pi = F.softmax(pi, dim=2)\n",
    "        # transform sigmas with exponential to ensures they are all positive\n",
    "        sigma = torch.exp(self.z_sigma(z)).view(-1, seq_len, self.n_gaussians, self.z_dim)\n",
    "        # compute mus\n",
    "        mu = self.z_mu(z).view(-1, seq_len, self.n_gaussians, self.z_dim)\n",
    "        return pi, sigma, mu\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.hidden = None\n",
    "        self.cell = None\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22734619",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2d6ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_mdnrnn(out_pi, out_sigma, out_mu, y):\n",
    "    # log-likelihood of output and ground truth\n",
    "    seq_len = y.shape[1]\n",
    "    latent_dim = y.shape[2]\n",
    "    y = y.view(-1, seq_len, 1, latent_dim)\n",
    "    loss = torch.distributions.Normal(loc=out_mu, scale=out_sigma)\n",
    "    loss = torch.exp(loss.log_prob(y))\n",
    "    loss = torch.sum(loss * out_pi, dim=2)\n",
    "    loss = -torch.log(1e-3 + loss)\n",
    "    return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daa6f30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# obtain trainset and testset\n",
    "trainset, testset = Create_dataset(None, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bb0481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to run sequences in batch they need to be padded in order to have the same sequence lenght\n",
    "def collate_fn_padd(batch):\n",
    "    len_x = [x.shape[0] for x,y in batch]\n",
    "    len_y = [y.shape[0] for x,y in batch]\n",
    "    \n",
    "    # padding the sequences to the same lenght\n",
    "    x = nn.utils.rnn.pad_sequence([t[0] for t in batch], batch_first=True)\n",
    "    y = nn.utils.rnn.pad_sequence([t[1] for t in batch], batch_first=True)\n",
    "    \n",
    "    # packing the sequences to be given in input to the lstm\n",
    "    X = nn.utils.rnn.pack_padded_sequence(x, len_x, batch_first=True, enforce_sorted=False)\n",
    "    Y = nn.utils.rnn.pack_padded_sequence(y, len_y, batch_first=True, enforce_sorted=False)\n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba572375",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "hidden_units = 1024\n",
    "z_dim = 512\n",
    "n_gaussians = 16\n",
    "\n",
    "mdnrnn = MDNRNN(hidden_units=hidden_units, z_dim=z_dim, num_layers=1, n_gaussians=n_gaussians).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=mdrnn.parameters(), lr=lr)\n",
    "batch_size = 10\n",
    "i=0\n",
    "while(True):\n",
    "    losses = []\n",
    "    n_batch = 1\n",
    "    train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn_padd)\n",
    "    for x, y in train_loader:\n",
    "        # unpack y values\n",
    "        y, _ = nn.utils.rnn.pad_packed_sequence(y, batch_first=True)\n",
    "        \n",
    "        # run mdnrnn\n",
    "        x = x.to(device)\n",
    "        mdnrnn.reset_state()\n",
    "        res_pi, res_sigma, res_mu = mdrnn(x)\n",
    "        \n",
    "        # compute loss and backward\n",
    "        loss = loss_mdnrnn(res_pi, res_sigma, res_mu, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f\"EPOCH: {i+1} MEAN LOSSES EPOCH: {sum(losses)/len(losses)}\")\n",
    "    print(f\"Loss: {loss.item()}\")\n",
    "    i+=1\n",
    "    torch.save(mdnrnn, f\"./BACKUP_MODELS/mdrnn\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
